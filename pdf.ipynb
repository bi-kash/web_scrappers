{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import spacy\n",
    "import pdfplumber\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Need these: shop_name,language,year,brand,modell,condition,category_shop,stock_status,stock_text,stock_sizes,url-detail,price,rrp\n",
    "def get_driver():\n",
    "    chromeOptions = webdriver.ChromeOptions()\n",
    "\n",
    "    # Headless is faster. If headless is False then it opens a browser and you can see action of web driver. You can try making it False\n",
    "    chromeOptions.headless = False\n",
    "    chromeOptions.add_argument(\"--log-level=3\")\n",
    "\n",
    "    # installs chrome driver automatically if not present\n",
    "    s = Service(ChromeDriverManager().install())\n",
    "    # chromeOptions.add_argument(\"user-data-dir=/home/bikash/.config/google-chrome/Profile 1\")\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()), options=chromeOptions\n",
    "    )\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_already_downloaded = True\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "if not os.path.exists('pdfs'):\n",
    "    os.makedirs('pdfs')\n",
    "\n",
    "def get_pdf(pdf, path):\n",
    "    response = requests.get(pdf)\n",
    "    # Save the PDF to a file\n",
    "    with open(path, 'wb') as file:   \n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files():\n",
    "\n",
    "    base_url = 'https://dl.ncsbe.gov/?prefix=data/SampleBallots/'\n",
    "    driver = get_driver()\n",
    "\n",
    "    driver.get(base_url)\n",
    "\n",
    "\n",
    "\n",
    "    # wait for a tag to load\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.TAG_NAME, \"a\"))\n",
    "    )\n",
    "\n",
    "    date_links = {}\n",
    "    # get all a tags\n",
    "    for a_tag in driver.find_elements(By.TAG_NAME, \"a\")[1:-1]:\n",
    "        href = a_tag.get_attribute('href')\n",
    "        date = re.search(r'\\d{4}-\\d{2}-\\d{2}', href).group()\n",
    "        month = date.split('-')[1]\n",
    "        if month == '11':\n",
    "            # create dir if it doesnot exist within dir pdfs\n",
    "            path = f'pdfs/{date}'\n",
    "            if not os.path.exists(path) and not '.zip' in href:\n",
    "                os.mkdir(path)\n",
    "            \n",
    "            date_links[path] = href\n",
    "\n",
    "\n",
    "    file_urls = []\n",
    "    for pdf_path, url in date_links.items():\n",
    "        data = {}\n",
    "        if '.zip' in url:\n",
    "            zip_path = pdf_path + '.zip'\n",
    "            data['file_name'] = zip_path.split('/')[-1]\n",
    "            data['url'] = url\n",
    "\n",
    "            file_urls.append(data)\n",
    "\n",
    "            if os.path.exists(zip_path):\n",
    "                continue\n",
    "            response = requests.get(url)\n",
    "            with open(zip_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"a\"))\n",
    "        )\n",
    "\n",
    "        pdfs = [element.get_attribute('href') for element in driver.find_element(By.TAG_NAME, 'pre').find_elements(By.XPATH , \"//a[contains(text(), '.pdf')]\")]\n",
    "        pdf_paths = []\n",
    "        for pdf in pdfs:\n",
    "            data = {}\n",
    "            file_name = pdf.split('/')[-1]\n",
    "            data['file_name'] = file_name\n",
    "            data['url'] = pdf\n",
    "            file_urls.append(data)\n",
    "            path = pdf_path + '/'+ file_name\n",
    "            if os.path.exists(path):\n",
    "                continue\n",
    "            pdf_paths.append((pdf, path))\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            executor.map(lambda args: get_pdf(*args), pdf_paths)\n",
    "            \n",
    "    pd.DataFrame(file_urls).to_csv('pdfs/file_urls.csv', index=False)\n",
    "    driver.quit()\n",
    "\n",
    "if not files_already_downloaded:\n",
    "    download_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_columns(df):\n",
    "    # Assuming df is your DataFrame\n",
    "    columns = df.columns\n",
    "\n",
    "    # Extract office and candidate columns\n",
    "    office_columns = [col for col in columns if col.startswith('office')]\n",
    "    candidate_columns = [col for col in columns if col.startswith('candidate')]\n",
    "\n",
    "\n",
    "    # Sort office columns by the number\n",
    "    office_columns_sorted = sorted(office_columns, key=lambda x: int(x.replace('office', '')))\n",
    "    candidate_columns_sorted = sorted(candidate_columns, key=lambda x: int(x.replace('candidate', '').replace(' ', '')))\n",
    "\n",
    "    # Create a new list for the sorted columns\n",
    "    sorted_columns = []\n",
    "\n",
    "    # keep other columns at the beginning\n",
    "    sorted_columns.extend([col for col in columns if col not in office_columns + candidate_columns])\n",
    "\n",
    "    # Reorder the columns to match the desired pattern\n",
    "    for office in office_columns_sorted:\n",
    "        office_number = office.replace('office', '')\n",
    "        sorted_columns.append(office)\n",
    "        sorted_columns.extend([col for col in candidate_columns_sorted if col.startswith(f'candidate{office_number}_')])\n",
    "\n",
    "    # Reorder the DataFrame columns\n",
    "    df = df[sorted_columns]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def is_name(text):\n",
    "    \"\"\"\n",
    "    Check if the given text is recognized as a name by spaCy.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The text to check.\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if the text is recognized as a name, False otherwise.\n",
    "    \"\"\"\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Check if any entity in the text is labeled as \"PERSON\"\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def extract_starting_points(pdf):\n",
    "    margin = 26\n",
    "    starting_points = []\n",
    "    search_results = []\n",
    "    expressions = [r'\\b(?:NC\\s+)?Superior\\s+Court\\s+Judge\\b', r'\\b(?:NC\\s+)?District\\s+Court\\s+Judge\\b']\n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        if i>1:\n",
    "            break\n",
    "        \n",
    "        for expression in expressions:\n",
    "            pattern = re.compile(expression, re.IGNORECASE)\n",
    "            search_results.extend(page.search(pattern=pattern))\n",
    "        if search_results:\n",
    "            for j in range(len(search_results)):\n",
    "                result = search_results[j]\n",
    "                k=1\n",
    "                while True:\n",
    "                    if j+k < len(search_results):\n",
    "                        next_search_result = search_results[j+k]\n",
    "                        if abs(next_search_result['x0'] - result['x0']) > margin:\n",
    "                            k += 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            top = next_search_result['top']\n",
    "                            break\n",
    "                        \n",
    "                    else: \n",
    "                        top = page.height - 48\n",
    "                        break\n",
    "                    \n",
    "\n",
    "                starting_points.append({'page': i, 'x0': result['x0'] - margin, 'y0': result['top'], 'x1': result['x1'] + margin, 'y1': top})\n",
    "    return starting_points\n",
    "\n",
    "def get_boxes(pdf, starting_point):\n",
    "    page = pdf.pages[starting_point['page']]\n",
    "    x0 = starting_point['x0']\n",
    "    y0 = starting_point['y0']\n",
    "    x1 = starting_point['x1']\n",
    "    y1 = starting_point['y1']\n",
    "    box = (x0, y0, x1, y1)\n",
    "    boxes = page.within_bbox(box)\n",
    "    boxes = boxes.extract_text_lines()\n",
    "    return boxes\n",
    "\n",
    "def get_office_name(boxes):\n",
    "    office = ''\n",
    "    a = 0\n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes[i]\n",
    "        a = i\n",
    "        if 'continue' in box['text'].lower() or 'next' in box['text'].lower():\n",
    "            break\n",
    "        if 'vote' not in box['text'].lower():\n",
    "            office = office + ' ' + box['text']\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return office.strip(), a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(boxes, is_last_element):\n",
    "    candidates = []\n",
    "    vote_found = False\n",
    "    skip = False\n",
    "    for i in range(len(boxes)):\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "        box = boxes[i]\n",
    "        if any(keyword in box['text'].lower() for keyword in ('continue', 'next')):\n",
    "            break\n",
    "        next_box = boxes[i+1] if i+1 < len(boxes) else None\n",
    "       \n",
    "        if next_box:\n",
    "            if 'vote' in next_box['text'].lower() or 'vote' in box['text'].lower():\n",
    "                vote_found = True\n",
    "                break\n",
    "\n",
    "            \n",
    "            elif abs(next_box['top'] - box['bottom']) < 2.5:\n",
    "                skip = True\n",
    "                if next_box['chars'][0]['height'] < box['chars'][0]['height']:\n",
    "                    candidate_name = box['text']\n",
    "                    candidates.append(candidate_name)\n",
    "                    continue    \n",
    "                    \n",
    "                candidate_name = box['text'] + ' ' + next_box['text']\n",
    "                candidates.append(candidate_name)\n",
    "                \n",
    "            else:\n",
    "                candidate_name = box['text']\n",
    "                candidates.append(candidate_name)\n",
    "        else:\n",
    "            candidate_name = box['text']\n",
    "            candidates.append(candidate_name)\n",
    "        \n",
    "\n",
    "    if is_last_element or vote_found:\n",
    "        for candidate in candidates[1:]:\n",
    "            if not is_name(candidate):\n",
    "                index = candidates.index(candidate)\n",
    "                return candidates[:index]\n",
    "\n",
    "    for candidate in candidates:\n",
    "        if len(candidate.split(' ')) == 1:\n",
    "            candidates.remove(candidate)  \n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path, pdf_file=None, pdf_url=None):\n",
    "    try:\n",
    "        pdf = pdfplumber.open(pdf_path)\n",
    "        starting_points = extract_starting_points(pdf)\n",
    "        data = {\n",
    "            'pdf_file': pdf_file,\n",
    "            'pdf_url': pdf_url\n",
    "        }\n",
    "        count = 0\n",
    "\n",
    "        for starting_point in starting_points:\n",
    "            \n",
    "\n",
    "            boxes = get_boxes(pdf, starting_point)\n",
    "\n",
    "            office, i = get_office_name(boxes)\n",
    "\n",
    "            if 'court' not in office.lower():\n",
    "                continue\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "            data[f'office{count}'] = office\n",
    "            boxes = boxes[i+1:]\n",
    "            if count == len(starting_points):\n",
    "                candidates = get_candidates(boxes, True)\n",
    "            else:\n",
    "                candidates = get_candidates(boxes, False)\n",
    "                    \n",
    "            for i in range(len(candidates)):\n",
    "                data[f'candidate{count}_{i+1}'] = candidates[i]\n",
    "    \n",
    "        return data\n",
    "    except Exception:\n",
    "        print(pdf_file, pdf_url)\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_csv_already_exists_for_date(date):\n",
    "    # find all csvs inside data data directory\n",
    "    csvs = [f for f in os.listdir('data') if f.endswith('.csv')]\n",
    "\n",
    "    for csv in csvs:\n",
    "        if date in csv:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ZIP file: pdfs/2012-11-06.zip\n",
      "Processing ZIP file: pdfs/2014-11-04.zip\n",
      "Processing ZIP file: pdfs/2011-11-08.zip\n",
      "Extracting for:  data/2012-11-06_sample_ballots.csv\n",
      "Extracting for:  data/2014-11-04_sample_ballots.csv\n",
      "Extracting for:  data/2011-11-08_sample_ballots.csv\n",
      "Extracting for:  data/2017-11-07_sample_ballots.csv\n",
      "Extracting for:  data/2021-11-02_sample_ballots.csv\n",
      "Extracting for:  data/2020-11-03_sample_ballots.csv\n",
      "Extracting for:  data/2024-11-05_sample_ballots.csv\n",
      "Extracting for:  data/2019-11-05_sample_ballots.csv\n",
      "Extracting for:  data/2023-11-07_sample_ballots.csv\n",
      "Extracting for:  data/2018-11-06_sample_ballots.csv\n",
      "Extracting for:  data/2022-11-08_sample_ballots.csv\n"
     ]
    }
   ],
   "source": [
    "file_to_process = {}\n",
    "df = pd.read_csv('pdfs/file_urls.csv')\n",
    "# Traverse the directory tree\n",
    "dates = []\n",
    "count = 0\n",
    "\n",
    "for root, dirs, files in os.walk('pdfs'):\n",
    "    if not root == 'pdfs':\n",
    "        date = root.split('/')[-1]\n",
    "        if date in dates:\n",
    "            continue\n",
    "\n",
    "        dates.append(date)\n",
    "        if check_if_csv_already_exists_for_date(date):\n",
    "            continue\n",
    "        file_to_process[date] = []\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        if file_name.endswith('.pdf'):\n",
    "            \n",
    "            \n",
    "            url = df[df['file_name'] == file_name]['url'].values[0]\n",
    "            file_to_process[date].append((file_path, file_name, url))\n",
    "            '''\n",
    "            if len(file_to_process[date]) == 10:\n",
    "                break\n",
    "            '''\n",
    "        elif file_name.endswith('.zip'):\n",
    "            date = file_name.replace('.zip', '')\n",
    "            if date in dates:\n",
    "                continue\n",
    "            dates.append(date)\n",
    "\n",
    "            if check_if_csv_already_exists_for_date(date):\n",
    "                continue\n",
    "\n",
    "            file_to_process[date] = []\n",
    "            print(f\"Processing ZIP file: {file_path}\")\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                for zip_file_name in zip_ref.namelist():\n",
    "                    if zip_file_name.endswith('.pdf'):\n",
    "                        pdf_file = zip_ref.open(zip_file_name)\n",
    "                        url = df[df['file_name'] == file_name]['url'].values[0]\n",
    "                        file_to_process[date].append((pdf_file, zip_file_name.split('/')[-1], url))\n",
    "                        '''\n",
    "                        if len(file_to_process[date]) == 10:\n",
    "                            break\n",
    "                        '''\n",
    "\n",
    "\n",
    "for date, files in file_to_process.items():\n",
    "    csv_file_name = 'data/'+ date+'_sample_ballots.csv'\n",
    "    if os.path.exists(csv_file_name):\n",
    "        continue\n",
    "    print('Extracting for: ', csv_file_name)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        all_data = list(executor.map(lambda args: process_pdf(*args), files))\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df = sort_columns(df)\n",
    "        df.to_csv(csv_file_name, index=False)\n",
    "        all_data = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_pdf('pdfs/2010-11-02/0GALEX03.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
